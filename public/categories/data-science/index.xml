<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science on The Stats Guy</title>
    <link>/categories/data-science/</link>
    <description>Recent content in Data Science on The Stats Guy</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 17 Mar 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/data-science/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Seven tips for working on analytics delivery projects</title>
      <link>/2019/03/17/seven-tips-for-working-on-analytics-delivery-projects/</link>
      <pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/03/17/seven-tips-for-working-on-analytics-delivery-projects/</guid>
      <description>Following are seven tips / tricks / hacks that I came to learnt (some of them the hard way) and compiled as a data scientist / delivery consultant / data science consultant. In brief, they are:
You to Yourself
 Develop a strategy
 Keep a delivery journal
 Plan your daily activities
 Frontload your projects
  You to Others
 Show mediocre output to no one</description>
    </item>
    
    <item>
      <title>Paper Review: To Tune or Not to Tune the Number of Trees in Random Forest</title>
      <link>/2019/02/24/paper-review-to-tune-or-not-to-tune-the-number-of-trees-in-random-forest/</link>
      <pubDate>Sun, 24 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/02/24/paper-review-to-tune-or-not-to-tune-the-number-of-trees-in-random-forest/</guid>
      <description>Plotting different performance metrics against the number of trees in random forest. Source. I came across the following paper during my Masters coursework that addresses a practical issue in the use of the random forest model, and in general, any other bootstrap aggregating ensembles:
Probst, P. &amp;amp; Boulestix, A-L. (2018). To Tune or Not to Tune the Number of Trees in Random Forest. Journal of Machine Learning Research, 18(181), 1-18.</description>
    </item>
    
    <item>
      <title>My Master of Science in Statistics programme in NUS</title>
      <link>/2019/02/09/my-master-of-science-in-statistics-programme-in-nus/</link>
      <pubDate>Sat, 09 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/02/09/my-master-of-science-in-statistics-programme-in-nus/</guid>
      <description>I have gotten quite a couple of questions regarding my current MSc Statistics programme in NUS. Here are some broadstroke information about the programme and how I am approaching it.
 I&amp;rsquo;m doing the MSc by Coursework programme, which means a research thesis is not part of my curriculum. A MSc by Research option is available.
 Under the Coursework programme, there is a Track 1 (40MC) programme and a Track 2 (80MC) one.</description>
    </item>
    
    <item>
      <title>The Machine Learning Life Cycle - how to run a ML project</title>
      <link>/2019/01/20/the-machine-learning-life-cycle-how-to-run-a-ml-project/</link>
      <pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/20/the-machine-learning-life-cycle-how-to-run-a-ml-project/</guid>
      <description>The Machine Learning Life Cycle from DataRobot.
I recently came across this page in the DataRobot Artificial Intelligence Wiki. If you don&#39;t already know, DataRobot is currently one of the top automated machine learning platform in the market, with emphasis on supervised learning and citizen data science. I am quite a big fan of their platform - even though I don&#39;t use it in my work, I believe that they and their competitors in the market are heading into the right direction towards automated machine learning.</description>
    </item>
    
    <item>
      <title>A repertoire of data scientist interview questions - with a twist</title>
      <link>/2018/12/28/a-repertoire-of-data-scientist-interview-questions-with-a-twist/</link>
      <pubDate>Fri, 28 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/28/a-repertoire-of-data-scientist-interview-questions-with-a-twist/</guid>
      <description>Machine Learning. Nothing to do with my intended topic, just a random xkcd comic that I thought is funny. Source.
(This post will be continually updated so as to capture more questions and answers along the way. To be honest I don&amp;rsquo;t think I have the best answers to some of these questions as well. Still learning. If you think that there&amp;rsquo;s a better way to tackle these questions, or maybe even that the question is set out in the wrong way in the first place, feel free to reach out or leave a comment.</description>
    </item>
    
    <item>
      <title>Why ensemble modelling works so well - and one often neglected principle</title>
      <link>/2018/12/25/why-ensemble-modelling-works-so-well-and-one-often-neglected-principle/</link>
      <pubDate>Tue, 25 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/25/why-ensemble-modelling-works-so-well-and-one-often-neglected-principle/</guid>
      <description>Putting models together in an ensemble learning fashion is a popular technique amongst Data Scientists
Ensemble learning is the simultaneous use of multiple predictive models to arrive at a single prediction, based on a collective decision made together by all models in the ensemble. It&#39;s a common and popular technique used in predictive modelling, especially when individual models are failing to produce the required performance levels, in terms of e.g. accuracy.</description>
    </item>
    
  </channel>
</rss>